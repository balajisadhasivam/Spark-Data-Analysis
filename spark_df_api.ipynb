{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "import json\n",
    "import findspark\n",
    "findspark.init('C:\\BigData\\spark-3.1.2-bin-hadoop3.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, explode, to_date\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql.types import StructType, StructField, StringType, MapType, DoubleType\n",
    "from pyspark.sql.functions import count, sum, avg, min, max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "# Retrieve the API key from environment variables\n",
    "api_key = os.getenv(\"ALPHA_VANTAGE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Meta Data\": {\n",
      "        \"1. Information\": \"Daily Prices (open, high, low, close) and Volumes\",\n",
      "        \"2. Symbol\": \"JPM\",\n",
      "        \"3. Last Refreshed\": \"2024-07-12\",\n",
      "        \"4. Output Size\": \"Full size\",\n",
      "        \"5. Time Zone\": \"US/Eastern\"\n",
      "    },\n",
      "    \"Time Series (Daily)\": {\n",
      "        \"2024-07-12\": {\n",
      "            \"1. open\": \"204.0000\",\n",
      "            \"2. high\": \"207.4500\",\n",
      "            \"3. low\": \"202.1000\",\n",
      "            \"4. close\": \"204.9400\",\n",
      "            \"5. volume\": \"15443441\"\n",
      "        },\n",
      "        \"2024-07-11\": {\n",
      "            \"1. open\": \"206.2100\",\n",
      "            \"2. high\": \"208.1000\",\n",
      "            \"3. low\": \"205.3800\",\n",
      "            \"4. close\": \"207.4500\",\n",
      "            \"5. volume\": \"10666937\"\n",
      "        },\n",
      "        \"2024-07-10\": {\n",
      "            \"1. open\": \"206.1400\",\n",
      "            \"2. high\": \"207.9700\",\n",
      "            \"3. low\": \"205.5800\",\n",
      "            \"4. close\": \"207.8000\",\n",
      "            \"5. volume\": \"8328493\"\n",
      "        },\n",
      "        \"2024-07-09\": {\n",
      "            \"1. open\": \"205.6300\",\n",
      "            \"2. high\": \"209.7600\",\n",
      "            \"3. low\": \"205.4500\",\n",
      "            \"4. close\": \"207.6300\",\n",
      "            \"5. volume\": \"9060258\"\n",
      "        },\n",
      "        \"2024-07-08\": {\n",
      "            \"1. open\": \"205.0400\",\n",
      "            \"2. high\": \"206.9000\",\n",
      "            \"3. low\": \"203.9700\",\n",
      "            \"4. close\": \"205.1700\",\n",
      "            \"5. volume\": \"8706967\"\n",
      "        },\n",
      "        \"2024-07-05\": {\n",
      "            \"1. open\": \"206.9900\",\n",
      "            \"2. high\": \"207.3700\",\n",
      "            \"3. low\": \"204.5200\",\n",
      "            \"4. close\": \"204.7900\",\n",
      "            \"5. volume\": \"8093096\"\n",
      "        },\n",
      "        \"2024-07-03\": {\n",
      "            \"1. open\": \"209.5500\",\n",
      "            \"2. high\": \"210.3800\",\n",
      "            \"3. low\": \"207.6500\",\n",
      "            \"4. close\": \"208.6900\",\n",
      "            \"5. volume\": \"5560925\"\n",
      "        },\n",
      "        \"2024-07-02\": {\n",
      "            \"1. open\": \"205.2900\",\n",
      "            \"2. high\": \"208.8600\",\n",
      "            \"3. low\": \"204.7700\",\n",
      "            \"4. close\": \"208.8300\",\n",
      "            \"5. volume\": \"7802936\"\n",
      "        },\n",
      "        \"2024-07-01\": {\n",
      "           \n"
     ]
    }
   ],
   "source": [
    "# Fetch JSON data from API\n",
    "url = \"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol=JPM&apikey={api_key}&outputsize=full\"\n",
    "response = requests.get(url)\n",
    "json_data = response.json()\n",
    "\n",
    "# Print a portion of the JSON data to understand its structure\n",
    "print(json.dumps(json_data, indent=4)[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the schema\n",
    "schema = StructType([\n",
    "    StructField(\"Meta Data\", StructType([\n",
    "        StructField(\"1. Information\", StringType(), True),\n",
    "        StructField(\"2. Symbol\", StringType(), True),\n",
    "        StructField(\"3. Last Refreshed\", StringType(), True),\n",
    "        StructField(\"4. Output Size\", StringType(), True),\n",
    "        StructField(\"5. Time Zone\", StringType(), True)\n",
    "    ]), True),\n",
    "    StructField(\"Time Series (Daily)\", MapType(StringType(), StructType([\n",
    "        StructField(\"1. open\", StringType(), True),\n",
    "        StructField(\"2. high\", StringType(), True),\n",
    "        StructField(\"3. low\", StringType(), True),\n",
    "        StructField(\"4. close\", StringType(), True),\n",
    "        StructField(\"5. volume\", StringType(), True)\n",
    "    ])), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"StockMarketDataAnalysis\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert JSON data to a Spark DataFrame with schema\n",
    "df = spark.read.schema(schema).json(spark.sparkContext.parallelize([json_data]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Meta Data: struct (nullable = true)\n",
      " |    |-- 1. Information: string (nullable = true)\n",
      " |    |-- 2. Symbol: string (nullable = true)\n",
      " |    |-- 3. Last Refreshed: string (nullable = true)\n",
      " |    |-- 4. Output Size: string (nullable = true)\n",
      " |    |-- 5. Time Zone: string (nullable = true)\n",
      " |-- Time Series (Daily): map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: struct (valueContainsNull = true)\n",
      " |    |    |-- 1. open: string (nullable = true)\n",
      " |    |    |-- 2. high: string (nullable = true)\n",
      " |    |    |-- 3. low: string (nullable = true)\n",
      " |    |    |-- 4. close: string (nullable = true)\n",
      " |    |    |-- 5. volume: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the schema of the DataFrame\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the nested structure\n",
    "df_flat = df.select(explode(col(\"Time Series (Daily)\")).alias(\"date\", \"data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+------+--------+------+-----------+\n",
      "|      date|  open|  high|     low| close|     volume|\n",
      "+----------+------+------+--------+------+-----------+\n",
      "|2024-07-12| 204.0|207.45|   202.1|204.94|1.5443441E7|\n",
      "|2024-07-11|206.21| 208.1|  205.38|207.45|1.0666937E7|\n",
      "|2024-07-10|206.14|207.97|  205.58| 207.8|  8328493.0|\n",
      "|2024-07-09|205.63|209.76|  205.45|207.63|  9060258.0|\n",
      "|2024-07-08|205.04| 206.9|  203.97|205.17|  8706967.0|\n",
      "|2024-07-05|206.99|207.37|  204.52|204.79|  8093096.0|\n",
      "|2024-07-03|209.55|210.38|  207.65|208.69|  5560925.0|\n",
      "|2024-07-02|205.29|208.86|  204.77|208.83|  7802936.0|\n",
      "|2024-07-01|202.84|207.09|  202.66|205.45|1.0205836E7|\n",
      "|2024-06-28|200.01| 202.6|199.3018|202.26|1.5307616E7|\n",
      "|2024-06-27|197.44|199.86|   196.9|199.17|  7913453.0|\n",
      "|2024-06-26|197.45|197.94| 196.275|197.43|  7758582.0|\n",
      "|2024-06-25|198.09|200.07|  197.74|198.07|  6915909.0|\n",
      "|2024-06-24|197.81|199.23|   197.1|198.88|  9785929.0|\n",
      "|2024-06-21|196.71|197.17|  194.22| 196.3|2.0972495E7|\n",
      "|2024-06-20|196.39|199.45|  196.11|198.67|  8731062.0|\n",
      "|2024-06-18| 194.6|197.96|  194.13| 197.0|  9022971.0|\n",
      "|2024-06-17|193.48|195.58|  192.64|194.98|  8725445.0|\n",
      "|2024-06-14|191.45|194.86|  191.42|193.78|  6874029.0|\n",
      "|2024-06-13|192.32|194.58|  190.88|193.66|  8587786.0|\n",
      "+----------+------+------+--------+------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Adjust the column selection based on the schema using backticks\n",
    "df_flat = df_flat.select(\n",
    "    col(\"date\"),\n",
    "    col(\"data.`1. open`\").alias(\"open\").cast(DoubleType()),\n",
    "    col(\"data.`2. high`\").alias(\"high\").cast(DoubleType()),\n",
    "    col(\"data.`3. low`\").alias(\"low\").cast(DoubleType()),\n",
    "    col(\"data.`4. close`\").alias(\"close\").cast(DoubleType()),\n",
    "    col(\"data.`5. volume`\").alias(\"volume\").cast(DoubleType())\n",
    ")\n",
    "\n",
    "df_flat.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: string (nullable = false)\n",
      " |-- open: double (nullable = true)\n",
      " |-- high: double (nullable = true)\n",
      " |-- low: double (nullable = true)\n",
      " |-- close: double (nullable = true)\n",
      " |-- volume: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_flat.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date column to date type\n",
    "df_flat = df_flat.withColumn(\"symbol\", lit(\"JPM\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-----------------+-----------------+-----------------+-----------------+--------------------+------+\n",
      "|summary|      date|             open|             high|              low|            close|              volume|symbol|\n",
      "+-------+----------+-----------------+-----------------+-----------------+-----------------+--------------------+------+\n",
      "|  count|      6213|             6213|             6213|             6213|             6213|                6213|  6213|\n",
      "|   mean|      null| 69.9840859488169|70.73050180267185|69.20185910188319|69.97511115403191|1.9603391131981328E7|  null|\n",
      "| stddev|      null|41.86119984262006|42.17952110198497|41.59444170915082| 41.8983194337179|1.8591209702773754E7|  null|\n",
      "|    min|1999-11-01|            15.35|            16.35|            14.96|            15.45|            773600.0|   JPM|\n",
      "|    max|2024-07-12|           209.55|           210.38|           207.65|           208.83|          2.172942E8|   JPM|\n",
      "+-------+----------+-----------------+-----------------+-----------------+-----------------+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_flat.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+\n",
      "|      date|    JPM|\n",
      "+----------+-------+\n",
      "|1999-11-18|  83.37|\n",
      "|2020-02-26| 126.64|\n",
      "|2019-08-23| 106.02|\n",
      "|2016-08-17|  65.89|\n",
      "|2009-06-23|  33.57|\n",
      "|2008-11-19|  28.47|\n",
      "|2014-05-27|  55.14|\n",
      "|2022-10-05| 110.39|\n",
      "|2007-09-13|   45.6|\n",
      "|2002-05-13|  36.34|\n",
      "|2010-09-24|39.7525|\n",
      "|2007-03-06|  48.52|\n",
      "|2003-05-29|  32.27|\n",
      "|2019-08-22| 108.72|\n",
      "|2017-12-05| 105.72|\n",
      "|2001-11-16|  39.41|\n",
      "|2023-05-18|  139.5|\n",
      "|2008-12-03|  30.25|\n",
      "|2002-06-21|  32.99|\n",
      "|2009-12-04|  41.74|\n",
      "+----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform the pivot operation\n",
    "pivot_df = df_flat.groupBy(\"date\").pivot(\"symbol\").sum(\"close\")\n",
    "pivot_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|      date|avg_close|\n",
      "+----------+---------+\n",
      "|2024-01-19|   170.31|\n",
      "|2023-05-18|    139.5|\n",
      "|2023-05-01|    141.2|\n",
      "|2022-10-05|   110.39|\n",
      "|2021-11-03|   170.53|\n",
      "|2020-04-13|    98.19|\n",
      "|2020-02-26|   126.64|\n",
      "|2019-08-23|   106.02|\n",
      "|2019-08-22|   108.72|\n",
      "|2019-08-08|   109.86|\n",
      "|2017-12-05|   105.72|\n",
      "|2016-08-17|    65.89|\n",
      "|2015-05-01|    63.61|\n",
      "|2014-05-27|    55.14|\n",
      "|2013-03-14|     51.0|\n",
      "|2010-09-24|  39.7525|\n",
      "|2010-02-12|    38.95|\n",
      "|2009-12-04|    41.74|\n",
      "|2009-06-23|    33.57|\n",
      "|2008-12-03|    30.25|\n",
      "+----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check average close price by date\n",
    "agg_df = df_flat.groupBy(\"date\").agg(avg(\"close\").alias(\"avg_close\"))\n",
    "agg_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------+--------+------+--------+\n",
      "|      date|    open|    high|     low| close|  volume|\n",
      "+----------+--------+--------+--------+------+--------+\n",
      "|2024-07-12|204.0000|207.4500|202.1000|204.94|15443441|\n",
      "|2024-07-11|206.2100|208.1000|205.3800|207.45|10666937|\n",
      "|2024-07-10|206.1400|207.9700|205.5800| 207.8| 8328493|\n",
      "|2024-07-09|205.6300|209.7600|205.4500|207.63| 9060258|\n",
      "|2024-07-08|205.0400|206.9000|203.9700|205.17| 8706967|\n",
      "|2024-07-05|206.9900|207.3700|204.5200|204.79| 8093096|\n",
      "|2024-07-03|209.5500|210.3800|207.6500|208.69| 5560925|\n",
      "|2024-07-02|205.2900|208.8600|204.7700|208.83| 7802936|\n",
      "|2024-07-01|202.8400|207.0900|202.6600|205.45|10205836|\n",
      "|2024-06-28|200.0100|202.6000|199.3018|202.26|15307616|\n",
      "|2024-06-27|197.4400|199.8600|196.9000|199.17| 7913453|\n",
      "|2024-06-26|197.4500|197.9400|196.2750|197.43| 7758582|\n",
      "|2024-06-25|198.0900|200.0700|197.7400|198.07| 6915909|\n",
      "|2024-06-24|197.8100|199.2300|197.1000|198.88| 9785929|\n",
      "|2024-06-21|196.7100|197.1700|194.2200| 196.3|20972495|\n",
      "|2024-06-20|196.3900|199.4500|196.1100|198.67| 8731062|\n",
      "|2024-06-18|194.6000|197.9600|194.1300| 197.0| 9022971|\n",
      "|2024-06-17|193.4800|195.5800|192.6400|194.98| 8725445|\n",
      "|2024-06-14|191.4500|194.8600|191.4200|193.78| 6874029|\n",
      "|2024-06-13|192.3200|194.5800|190.8800|193.66| 8587786|\n",
      "+----------+--------+--------+--------+------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter rows based on a condition\n",
    "df_filtered = df_flat.filter(df_flat[\"close\"] > 143.00)\n",
    "df_filtered.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------+--------+------+--------+\n",
      "|      date|    open|    high|     low| close|  volume|\n",
      "+----------+--------+--------+--------+------+--------+\n",
      "|2024-07-12|204.0000|207.4500|202.1000|204.94|15443441|\n",
      "|2024-07-11|206.2100|208.1000|205.3800|207.45|10666937|\n",
      "|2024-07-10|206.1400|207.9700|205.5800| 207.8| 8328493|\n",
      "|2024-07-09|205.6300|209.7600|205.4500|207.63| 9060258|\n",
      "|2024-07-08|205.0400|206.9000|203.9700|205.17| 8706967|\n",
      "|2024-07-05|206.9900|207.3700|204.5200|204.79| 8093096|\n",
      "|2024-07-03|209.5500|210.3800|207.6500|208.69| 5560925|\n",
      "|2024-07-02|205.2900|208.8600|204.7700|208.83| 7802936|\n",
      "|2024-07-01|202.8400|207.0900|202.6600|205.45|10205836|\n",
      "|2024-06-28|200.0100|202.6000|199.3018|202.26|15307616|\n",
      "|2024-06-27|197.4400|199.8600|196.9000|199.17| 7913453|\n",
      "|2024-06-26|197.4500|197.9400|196.2750|197.43| 7758582|\n",
      "|2024-06-25|198.0900|200.0700|197.7400|198.07| 6915909|\n",
      "|2024-06-24|197.8100|199.2300|197.1000|198.88| 9785929|\n",
      "|2024-06-21|196.7100|197.1700|194.2200| 196.3|20972495|\n",
      "|2024-06-20|196.3900|199.4500|196.1100|198.67| 8731062|\n",
      "|2024-06-18|194.6000|197.9600|194.1300| 197.0| 9022971|\n",
      "|2024-06-17|193.4800|195.5800|192.6400|194.98| 8725445|\n",
      "|2024-06-14|191.4500|194.8600|191.4200|193.78| 6874029|\n",
      "|2024-06-13|192.3200|194.5800|190.8800|193.66| 8587786|\n",
      "+----------+--------+--------+--------+------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Handle null or invalid values in close column\n",
    "df_filtered = df_filtered.filter(df_filtered[\"close\"].isNotNull())\n",
    "df_filtered.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------+--------+------+--------+------------------+\n",
      "|      date|    open|    high|     low| close|  volume|       price_range|\n",
      "+----------+--------+--------+--------+------+--------+------------------+\n",
      "|2024-07-12|204.0000|207.4500|202.1000|204.94|15443441| 5.349999999999994|\n",
      "|2024-07-11|206.2100|208.1000|205.3800|207.45|10666937| 2.719999999999999|\n",
      "|2024-07-10|206.1400|207.9700|205.5800| 207.8| 8328493|2.3899999999999864|\n",
      "|2024-07-09|205.6300|209.7600|205.4500|207.63| 9060258| 4.310000000000002|\n",
      "|2024-07-08|205.0400|206.9000|203.9700|205.17| 8706967| 2.930000000000007|\n",
      "|2024-07-05|206.9900|207.3700|204.5200|204.79| 8093096|2.8499999999999943|\n",
      "|2024-07-03|209.5500|210.3800|207.6500|208.69| 5560925|2.7299999999999898|\n",
      "|2024-07-02|205.2900|208.8600|204.7700|208.83| 7802936| 4.090000000000003|\n",
      "|2024-07-01|202.8400|207.0900|202.6600|205.45|10205836| 4.430000000000007|\n",
      "|2024-06-28|200.0100|202.6000|199.3018|202.26|15307616|3.2982000000000085|\n",
      "|2024-06-27|197.4400|199.8600|196.9000|199.17| 7913453| 2.960000000000008|\n",
      "|2024-06-26|197.4500|197.9400|196.2750|197.43| 7758582| 1.664999999999992|\n",
      "|2024-06-25|198.0900|200.0700|197.7400|198.07| 6915909| 2.329999999999984|\n",
      "|2024-06-24|197.8100|199.2300|197.1000|198.88| 9785929|2.1299999999999955|\n",
      "|2024-06-21|196.7100|197.1700|194.2200| 196.3|20972495|2.9499999999999886|\n",
      "|2024-06-20|196.3900|199.4500|196.1100|198.67| 8731062| 3.339999999999975|\n",
      "|2024-06-18|194.6000|197.9600|194.1300| 197.0| 9022971|3.8300000000000125|\n",
      "|2024-06-17|193.4800|195.5800|192.6400|194.98| 8725445| 2.940000000000026|\n",
      "|2024-06-14|191.4500|194.8600|191.4200|193.78| 6874029| 3.440000000000026|\n",
      "|2024-06-13|192.3200|194.5800|190.8800|193.66| 8587786| 3.700000000000017|\n",
      "+----------+--------+--------+--------+------+--------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add a new column for the price range (high - low)\n",
    "df_with_range = df_filtered.withColumn(\"price_range\", df_filtered[\"high\"] - df_filtered[\"low\"])\n",
    "df_with_range.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+---------+---------+---------+---------+\n",
      "|      date|count|sum_close|avg_close|min_close|max_close|\n",
      "+----------+-----+---------+---------+---------+---------+\n",
      "|2023-06-22|    1|   139.58|   139.58|   139.58|   139.58|\n",
      "|2022-03-28|    1|   140.87|   140.87|   140.87|   140.87|\n",
      "|2021-10-11|    1|   166.64|   166.64|   166.64|   166.64|\n",
      "|2021-08-27|    1|   163.05|   163.05|   163.05|   163.05|\n",
      "|2021-06-22|    1|   150.21|   150.21|   150.21|   150.21|\n",
      "|2021-01-27|    1|   127.86|   127.86|   127.86|   127.86|\n",
      "|2020-08-24|    1|   100.06|   100.06|   100.06|   100.06|\n",
      "|2019-06-04|    1|   109.74|   109.74|   109.74|   109.74|\n",
      "|2019-05-08|    1|   112.61|   112.61|   112.61|   112.61|\n",
      "|2018-08-10|    1|   115.73|   115.73|   115.73|   115.73|\n",
      "|2017-09-11|    1|    89.79|    89.79|    89.79|    89.79|\n",
      "|2017-08-11|    1|    91.42|    91.42|    91.42|    91.42|\n",
      "|2016-03-01|    1|     59.2|     59.2|     59.2|     59.2|\n",
      "|2015-05-19|    1|    67.01|    67.01|    67.01|    67.01|\n",
      "|2015-03-09|    1|     61.5|     61.5|     61.5|     61.5|\n",
      "|2014-11-12|    1|    60.56|    60.56|    60.56|    60.56|\n",
      "|2014-09-26|    1|    60.56|    60.56|    60.56|    60.56|\n",
      "|2013-09-09|    1|    52.86|    52.86|    52.86|    52.86|\n",
      "|2013-05-21|    1|    53.02|    53.02|    53.02|    53.02|\n",
      "|2013-03-26|    1|    48.64|    48.64|    48.64|    48.64|\n",
      "+----------+-----+---------+---------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_flat.groupBy(\"date\").agg(\n",
    "    count(\"*\").alias(\"count\"),\n",
    "    sum(\"close\").alias(\"sum_close\"),\n",
    "    avg(\"close\").alias(\"avg_close\"),\n",
    "    min(\"close\").alias(\"min_close\"),\n",
    "    max(\"close\").alias(\"max_close\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning with Spark MLlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flat = df_flat.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "feature_columns = [\"open\", \"high\", \"low\", \"volume\"]\n",
    "if 'features' in df_flat.columns:\n",
    "    df_flat = df_flat.drop('features')\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "df_flat = assembler.transform(df_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features: StandardScaler\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "if 'scaledFeatures' in df_flat.columns:\n",
    "    df_flat = df_flat.drop('scaledFeatures')\n",
    "scaler_model = scaler.fit(df_flat)\n",
    "df_flat = scaler_model.transform(df_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "train_data, test_data = df_flat.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'scaledFeatures' in train_data.columns:\n",
    "    train_data = train_data.drop('scaledFeatures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(featuresCol=\"scaledFeatures\", labelCol=\"close\")\n",
    "param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.01, 0.1, 1.0]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0]) \\\n",
    "    .build()\n",
    "\n",
    "crossval = CrossValidator(estimator=lr,\n",
    "                          estimatorParamMaps=param_grid,\n",
    "                          evaluator=RegressionEvaluator(labelCol=\"close\"),\n",
    "                          numFolds=3)\n",
    "\n",
    "train_data = scaler_model.transform(train_data)\n",
    "\n",
    "cv_model = crossval.fit(train_data)\n",
    "best_model = cv_model.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----------------+\n",
      "|            features|close|       prediction|\n",
      "+--------------------+-----+-----------------+\n",
      "|[83.62,84.0,82.19...|82.44|82.83237680222356|\n",
      "|[82.38,84.12,81.9...|83.37|83.41690041734047|\n",
      "|[82.5,82.56,80.69...|81.87|81.17370778982134|\n",
      "|[79.75,79.94,78.7...|79.56|79.13507468370776|\n",
      "|[77.13,78.0,76.56...|77.39|77.37954473045431|\n",
      "|[80.94,83.37,80.8...| 82.0| 82.7587705661341|\n",
      "|[78.5,79.19,77.37...|78.63|78.18594276435968|\n",
      "|[78.12,79.25,77.7...|78.53|78.72642147872777|\n",
      "|[72.63,73.5,71.0,...|72.75|72.08758316950515|\n",
      "|[75.38,79.0,75.0,...|78.44|77.96111994700654|\n",
      "|[79.44,81.5,78.56...|80.69|80.40265816580782|\n",
      "|[83.5,84.87,80.25...|83.19|82.13642209650591|\n",
      "|[83.13,83.75,81.3...|83.13|82.29323448514629|\n",
      "|[77.25,77.56,74.6...| 76.0| 75.5110520632515|\n",
      "|[79.88,82.0,78.87...| 82.0|80.79389053793474|\n",
      "|[82.94,84.38,82.2...|83.44|83.55023622206548|\n",
      "|[80.5,80.94,78.5,...| 79.0|79.33492438929345|\n",
      "|[90.0,90.5,84.5,5...|86.56|86.25613355106269|\n",
      "|[97.0,100.75,96.0...|96.19|99.20906322561714|\n",
      "|[94.25,94.5,89.31...|90.38|90.72388101771074|\n",
      "+--------------------+-----+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = lr_model.transform(test_data)\n",
    "predictions.select(\"features\", \"close\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE): 0.6349903628665771\n",
      "R²: 0.9997737308447905\n",
      "Accuracy: 0.990925482612399\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "predictions = best_model.transform(test_data)\n",
    "\n",
    "evaluator_rmse = RegressionEvaluator(labelCol=\"close\", metricName=\"rmse\")\n",
    "rmse = evaluator_rmse.evaluate(predictions)\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n",
    "evaluator_r2 = RegressionEvaluator(labelCol=\"close\", metricName=\"r2\")\n",
    "r2 = evaluator_r2.evaluate(predictions)\n",
    "print(f\"R²: {r2}\")\n",
    "\n",
    "# Calculating accuracy as the inverse of error for regression\n",
    "accuracy = 1 - rmse / df_flat.select(\"close\").rdd.map(lambda row: row[0]).mean()\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
